<div class="cover" style="page-break-after:always;font-family:方正公文仿宋;width:100%;height:100%;border:none;margin: 0 auto;text-align:center;">
    <div style="width:50%;margin: 0 auto;height:0;padding-bottom:10%;">
        </br>
        <img src="../sysu-name.png" alt="校名" style="width:100%;"/>
    </div>
    </br></br>
    <div style="width:40%;margin: 0 auto;height:0;padding-bottom:40%;">
        <img src="../sysu.png" alt="校徽" style="width:100%;"/>
    </div>
		</br></br></br>
    <span style="font-family:华文黑体Bold;text-align:center;font-size:20pt;margin: 10pt auto;line-height:30pt;">本科生实验报告</span>
    </br>
    </br>
    <table style="border:none;text-align:center;width:72%;font-family:仿宋;font-size:14px; margin: 0 auto;">
    <tbody style="font-family:方正公文仿宋;font-size:12pt;">
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">实验课程</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">并行程序设计与算法实验</td>
      </tr>
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">实验名称</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">3-Pthreads并行矩阵乘法与数组求和</td>
      </tr>
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">专业名称</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">计算机科学与技术</td>
      </tr>
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">学生姓名</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">李世源</td>
      </tr>
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">学生学号</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">22342043</td>
      </tr>
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">实验地点</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋"></td>
      </tr>
        <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">实验成绩</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋"></td>
      </tr>
      <tr style="font-weight:normal;"> 
            <td style="width:20%;text-align:center;">报告时间</td>
            <td style="width:40%;font-weight:normal;border-bottom: 1px solid;text-align:center;font-family:华文仿宋">2025年04月02日</td>
      </tr>
    </tbody>              
    </table>
</div>

<!-- 注释语句：导出PDF时会在这里分页，使用 Typora Newsprint 主题放大 125% -->



# 实验环境

我的测试平台处理器是 Intel Xeon E7 处理器，单槽 16 核，Intel 给出的性能信息如下：

| Processor Group                                              | GFLOPS | APP     |
| ------------------------------------------------------------ | ------ | ------- |
| Intel® Xeon® Processor E7-4830 v3 (30M Cache, 2.10 GHz) E7-4830V3 | 403.2  | 0.12096 |

# 代码介绍

- `test1` 目录下为并行矩阵乘法对 C 按行划分实现。
- `test2` 目录下为并行矩阵乘法对 C 按块划分实现。
- `test3` 目录下为并行数组求和每个线程单独求和，最后相加的实现。
- `test4` 目录下为并行数组求和通过全局求和值及其锁的实现。

`Makefile` 中定义了开发、构建、测试，使用如下：

```shell
# 生成 LSP 配置文件，本实验不需要链接所以这个不太需要
make dev

# 只构建不测试
make build

# 运行单次测试
./build/test1 2048 2048 2048 16  # 并行矩阵乘法
./build/test2 0x1p27 # 并行数组求和, 128M = 0x1p27

# 运行表格上的全部测试，输出表格形式的结果
make test1  # 并行矩阵乘法
make test2  # 并行数组求和

# 清空已构建内容(build 目录)
make clean
```

使用 jupyter notebook 脚本 `draw.ipynb` 根据 `make test1` 或 `make test2` 输出的结果 (`build/result.md`) 画图，直观展示性能变化情况。实验报告中的曲线图均由该脚本生成。

# 并行矩阵乘法

## 实验要求

使用 Pthreads 实现并行矩阵乘法，并通过实验分析其性能。

输入：$m,n,k$ 三个整数，每个整数的取值范围均为 $[128, 2048]$。

问题描述：随机生成 $m\times n$ 的矩阵 $A$ 及 $n\times k$ 的矩阵 $B$，并对这两个矩阵进行矩阵乘法运算，得到矩阵 $C$。

输出： $A,B,C$ 三个矩阵，及矩阵计算所消耗的时间 $t$。

要求：
1. 使用 Pthreads 创建多线程实现并行矩阵乘法，调整线程数量（1-16）及矩阵规模（128-2048），根据结果分析其并行性能（包括但不限于，时间、效率、可扩展性）。
2. 选做：可分析不同数据及任务划分方式的影响。

## 测试分析

按照 A 矩阵行划分计算，得到测试结果如下：

|    |     128     |     256     |     512     |     1024    |     2048    |
|----|-------------|-------------|-------------|-------------|-------------|
|  1 | 1.11776e-03 | 1.18844e-02 | 8.65336e-02 | 6.30368e-01 | 5.68360e+00 |
|  2 | 1.46766e-03 | 5.87945e-03 | 4.50713e-02 | 3.62203e-01 | 3.54966e+00 |
|  4 | 8.85635e-04 | 3.83457e-03 | 2.27392e-02 | 1.78856e-01 | 2.09500e+00 |
|  8 | 1.33344e-03 | 2.41976e-03 | 1.47262e-02 | 8.92969e-02 | 1.14147e+00 |
| 16 | 1.51407e-03 | 2.48741e-03 | 9.83513e-03 | 4.69817e-02 | 7.42013e-01 |

如下是相同矩阵规模下，随着线程数量增大，所消耗时间的变化情况：

![time-num_threads](images/time-num_threads.png)

对于较小的矩阵（如128×128），线程数量的增加并不总能带来性能提升。当线程从1增加到2时，计算时间反而略有上升，从1.12毫秒增加到1.47毫秒，这可能是因为线程创建和同步的开销超过了并行计算带来的收益。当线程数增加到4时，时间降至0.886毫秒，说明并行化开始发挥作用。然而，继续增加线程至8或16时，时间波动较大，甚至有所回升，这表明对于小矩阵，过多的线程反而可能因管理开销而降低效率。

而对于中等规模的矩阵（如256×256至1024×1024），增加线程数量能显著减少计算时间。例如，在256×256的矩阵上，使用1个线程需要11.88毫秒，而使用16个线程仅需2.49毫秒，加速比约为4.8倍。在1024×1024的矩阵上，加速比更为明显，从单线程的630毫秒降至16线程的47毫秒，加速比高达13.4倍，接近理想的线性加速。

对于更大的矩阵（如2048×2048），线程数量的增加仍然能大幅提升性能，但加速比有所下降。从1个线程的5.68秒减少到16个线程的0.742秒，加速比约为7.7倍。虽然仍然可观，但相比中等规模矩阵的加速比有所降低，这可能是因为大规模计算时内存带宽或缓存竞争成为瓶颈，限制了并行效率的进一步提升。

如下是相同线程数量下，随着矩阵规模增大，所消耗时间的变化情况：

![time-matrix_size](images/time-matrix_size.png)

当线程数量固定时，矩阵规模的增大会显著增加计算时间，但多线程能有效缓解这一趋势。

在单线程情况下，矩阵规模从128×128增加到2048×2048（即规模扩大16倍），计算时间从1.12毫秒激增至5.68秒，增长约5000倍，这与矩阵乘法的理论计算复杂度（O(n³)）相符。相比之下，使用16个线程时，同样的规模增长仅使计算时间从1.51毫秒增加到742毫秒，增长约500倍，远低于单线程的增长幅度。这说明多线程能有效降低大规模矩阵计算的时间成本。

此外，对比不同线程数下的表现可以发现，对于小矩阵（如128×128），多线程的优势并不明显，甚至可能因额外开销而变慢。而对于大矩阵（如2048×2048），16个线程的计算速度比单线程快7.7倍，充分体现了并行计算在高计算负载下的优势。

## 选作部分

`test3` 目录下代码为对 C 矩阵按块划分的方式，对于指定的线程数量 num_threads，找到一个最优的线程分配方案，将可用的线程数合理地划分到矩阵的行和列维度上。通过如下函数实现：

```cpp
pair<int, int> get_block_distribution(int num_threads, int M, int N) {
  int best_rows = 1;
  int best_cols = num_threads;
  double best_ratio_diff = fabs(1.0 - (double)(M*best_cols)/(N*best_rows));
  
  // 尝试所有可能的因数分解
  for (int rows = 1; rows <= num_threads; rows++) {
    if (num_threads % rows != 0) continue;
    int cols = num_threads / rows;
    double ratio = (double)(M*cols)/(N*rows);
    double ratio_diff = fabs(1.0 - ratio);
    
    if (ratio_diff < best_ratio_diff) {
      best_ratio_diff = ratio_diff;
      best_rows = rows;
      best_cols = cols;
    }
  }
  
  return {best_rows, best_cols};
}
```

然后修改线程参数和执行函数，使得从原来的仅有 M 行方向上下限增加 N 列方向的上下限。

通过 `make test3` 执行测试，得到结果如下：

|    |     128     |     256     |     512     |     1024    |     2048    |
|----|-------------|-------------|-------------|-------------|-------------|
|  1 | 1.25928e-03 | 1.23125e-02 | 8.46123e-02 | 6.10925e-01 | 7.66041e+00 |
|  2 | 1.24051e-03 | 6.01996e-03 | 4.32853e-02 | 3.44145e-01 | 3.27047e+00 |
|  4 | 7.61935e-04 | 3.91000e-03 | 2.41941e-02 | 1.82563e-01 | 1.73377e+00 |
|  8 | 1.18493e-03 | 3.32915e-03 | 2.15063e-02 | 1.23304e-01 | 1.05725e+00 |
| 16 | 2.16955e-03 | 3.72726e-03 | 1.29559e-02 | 9.16421e-02 | 9.08718e-01 |

此时性能并没有比单纯的按行划分更好，甚至会变得更差，主要是因为划分方式更加复杂，同时按块划分并没有减少总的计算量。相比先前的实验我还尝试了 Cannon 算法减少了进程间通信，此时线程间仅需要传递几个参数而不需要传递矩阵数据，通信开销也没有优化的余地。在这个场景下，原本简单的按行划分实现性能就基本足够好了。

# 并行数组求和

## 实验要求

使用 Pthreads 实现并行数组求和，并通过实验分析其性能。

输入：整数 $n$，取值范围为 $[1M, 128M]$。

问题描述：随机生成长度为 $n$ 的整型数组 $A$，计算其元素和 $s=\sum_{i=1}^{n}A_i$。

输出：数组 $A$，元素和 $s$，及求和计算所消耗的时间 $t$。

要求：
1. 使用 Pthreads 实现并行数组求和，调整线程数量（1-16）及数组规模（1M, 128M），根据结果分析其并行性能（包括但不限于，时间、效率、可扩展性）。
2. 选做：可分析不同聚合方式的影响。

## 测试分析

为了减少线程切换的开销，我增加了代码显式的绑核操作，main 函数一开始就绑核到 0 号核上，每创建一个线程就绑定到一个不同的核上。

均分数组，每个线程单独求和，最后相加实现，得到测试结果如下：

|        |      1      |      2      |      4      |      8      |      16     |
|--------|-------------|-------------|-------------|-------------|-------------|
| 0x1p20 | 1.48160e-03 | 1.89169e-03 | 1.29155e-03 | 1.61218e-03 | 2.89423e-03 |
| 0x1p21 | 2.73357e-03 | 2.78530e-03 | 1.71053e-03 | 1.58085e-03 | 3.63093e-03 |
| 0x1p22 | 5.63272e-03 | 4.54898e-03 | 2.84695e-03 | 2.03396e-03 | 2.59195e-03 |
| 0x1p23 | 1.14205e-02 | 8.69733e-03 | 4.55575e-03 | 5.02989e-03 | 3.34435e-03 |
| 0x1p24 | 2.05515e-02 | 1.57664e-02 | 8.87179e-03 | 5.63893e-03 | 4.32483e-03 |
| 0x1p25 | 4.07446e-02 | 2.93059e-02 | 1.64492e-02 | 1.13983e-02 | 7.31944e-03 |
| 0x1p26 | 7.76025e-02 | 5.75550e-02 | 3.01917e-02 | 2.03508e-02 | 1.29171e-02 |
| 0x1p27 | 1.54921e-01 | 1.08074e-01 | 5.87871e-02 | 3.21944e-02 | 2.48717e-02 |

如下为固定线程数量，随着数组规模增长，所消耗时间的变化情况：

![test2 time-array_size](images/test2-time-array_size.png)

考虑单线程情况下，计算量直接正比于数组规模，没有并行优化。时间随数组规模线性增长：

| 数组规模 | 时间（1线程, ms） | 增长比例（基准：1M） |
|----------|-------------------|----------------------|
| 1M (`0x1p20`) | 1.4816          | 1.0x                 |
| 128M (`0x1p27`) | 154.921        | ≈104.6x              |

考虑多线程（2/4/8/16线程）的性能，多线程的时间增长 整体仍然线性，但斜率比单线程低（并行加速）。

例如，16线程：

| 数组规模 | 时间（16线程, ms） | 增长比例（基准：1M） |
|----------|---------------------|----------------------|
| 1M (`0x1p20`) | 2.89423            | 1.0x（基准）         |
| 128M (`0x1p27`) | 24.8717           | ≈8.6x                |

（远低于单线程的 104.6 倍，说明并行优化有效）。
小规模数组（如 1M-4M）时，多线程加速不明显（甚至可能比单线程慢）。

大规模数组（如 32M-128M）时，多线程加速显著（16线程比单线程快 6.2 倍）。

如下为固定数组规模，随着线程数量增长，所消耗时间的变化情况：

![test2 time-num_threads](images/test2-time-num_threads.png)

对于小规模数组（1M-4M，`0x1p20`-`0x1p22`），线程数增加时，时间没有明显减少，甚至可能增加。

例如 1M 时，16线程 2.89423 ms 比单线程 1.4816 ms 慢了一倍。

原因和可能是并行开销（线程创建/同步） 超过计算收益。以及数据规模太小，无法充分利用多核。

对于中等规模数组（8M-32M，`0x1p23`-`0x1p25`），线程数增加时，时间 逐步减少，但加速比低于理论值

例如 32M (`0x1p25`) 下 16 线程相比单线程的加速比：

| 数组规模 | 时间（1线程, ms） | 时间（16线程, ms） | 加速比 |
|----------|-------------------|--------------------|--------|
| 32M (`0x1p25`) | 40.7446 | 7.31944 | ≈5.6x |

原因可能是并行计算开始发挥作用，但受限于内存带宽或负载均衡。

对于大规模数组（64M-128M，`0x1p26`-`0x1p27`），线程数增加时，时间 显著减少，接近线性加速。

例如 128M (`0x1p27`) 下 16 线程相比单线程的加速比：：

| 数组规模 | 时间（1线程, ms） | 时间（16线程, ms） | 加速比 |
|----------|-------------------|--------------------|--------|
| 128M (`0x1p27`) | 154.921 | 24.8717 | ≈6.2x |

说明计算密集型任务，并行化收益明显。但仍未达到理想线性加速（16线程理论加速比 16 倍），可能受 线程同步 或 内存访问竞争 影响。


## 选作部分

`test4` 目录下代码为设置一个全局求和值，每一个线程都向该值做加法。为了防止线程间争夺这个值产生冒险，还需要设置锁。每一次做加法都需要先（等待锁空闲）上锁，做完加法后解锁。

对比原本的实现，性能可能要更差一些，因为围绕锁的操作引入了新的开销。对于这个数组求和场景，原本每一个线程单独求和，最后相加的方式是开销最小的，没有必要的数据竞争，所以也每有必要引入锁。